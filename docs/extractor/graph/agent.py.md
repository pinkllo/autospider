# agent.py - LangGraph Agent

agent.py æ¨¡å—æä¾› LangGraph Agent å›¾å®šä¹‰ï¼Œå®ç°çº¯è§†è§‰ SoM æµè§ˆå™¨ Agentã€‚

---

## ğŸ“ æ–‡ä»¶è·¯å¾„

```
src/autospider/extractor/graph/agent.py
```

---

## ğŸ“‘ å‡½æ•°ç›®å½•

### ğŸš€ æ ¸å¿ƒç±»
- `GraphState` - LangGraph çŠ¶æ€å®šä¹‰
- `SoMAgent` - SoM çº¯è§†è§‰ Agent

### ğŸ”§ ä¸»è¦æ–¹æ³•
- `run()` - è¿è¡Œ Agent å¹¶è¿”å› XPath è„šæœ¬

### ğŸ” å†…éƒ¨æ–¹æ³•
- `_observe()` - è§‚å¯ŸèŠ‚ç‚¹ï¼šæ³¨å…¥ SoM + æˆªå›¾
- `_decide()` - å†³ç­–èŠ‚ç‚¹ï¼šè°ƒç”¨ LLM
- `_act()` - æ‰§è¡ŒèŠ‚ç‚¹ï¼šæ‰§è¡ŒåŠ¨ä½œ
- `_check_done()` - æ£€æŸ¥æ˜¯å¦å®Œæˆ
- `_generate_script()` - ç”Ÿæˆæœ€ç»ˆçš„ XPath è„šæœ¬

---

## ğŸš€ æ ¸å¿ƒåŠŸèƒ½

### SoMAgent

SoM çº¯è§†è§‰ Agentï¼Œä½¿ç”¨ LangGraph å®ç°è‡ªåŠ¨åŒ–ä»»åŠ¡ã€‚

```python
from autospider.extractor.graph.agent import SoMAgent, run_agent
from autospider.common.types import RunInput

# åˆ›å»ºè¿è¡Œè¾“å…¥
run_input = RunInput(
    start_url="https://example.com",
    task="æ”¶é›†å•†å“ä»·æ ¼ä¿¡æ¯",
    target_text="ä»·æ ¼",
    max_steps=20,
    output_dir="output"
)

# è¿è¡Œ Agent
script = await run_agent(page, run_input)

print(f"ä»»åŠ¡: {script.task}")
print(f"æ­¥éª¤æ•°: {len(script.steps)}")
print(f"æå–ç»“æœ: {script.extracted_result}")
```

### Agent æµç¨‹

Agent å®ç°å®Œæ•´çš„è‡ªåŠ¨åŒ–æµç¨‹ï¼š

**0. ä»»åŠ¡è§„åˆ’**
```python
# åˆ†æä»»åŠ¡å¹¶ç”Ÿæˆæ‰§è¡Œè®¡åˆ’
plan = await planner.plan(
    start_url,
    task,
    target_text
)
```

**1. å¯¼èˆªåˆ°èµ·å§‹é¡µé¢**
```python
await page.goto(start_url, wait_until="domcontentloaded", timeout=30000)
```

**2. Observe: æ³¨å…¥ SoM å¹¶æˆªå›¾**
```python
# æ³¨å…¥ SoM å¹¶æ‰«æ
snapshot = await inject_and_scan(page)

# æˆªå›¾ï¼ˆåŒ…å« SoM æ ‡æ³¨ï¼‰
screenshot_bytes, screenshot_base64 = await capture_screenshot_with_marks(page)
```

**3. Decide: è°ƒç”¨ LLM å†³ç­–**
```python
# è°ƒç”¨ LLM å†³ç­–
action = await decider.decide(
    agent_state,
    screenshot_base64,
    marks_text,
    target_found_in_page,
    scroll_info
)
```

**4. Act: æ‰§è¡ŒåŠ¨ä½œ**
```python
# æ‰§è¡ŒåŠ¨ä½œ
result, script_step = await executor.execute(
    action,
    mark_id_to_xpath,
    step_index
)
```

**5. Check: æ£€æŸ¥æ˜¯å¦å®Œæˆ**
```python
# æ£€æŸ¥æ˜¯å¦å®Œæˆ
if state["extracted_text"]:
    if target_text in state["extracted_text"]:
        state["done"] = True
        state["success"] = True
```

---

## ğŸ’¡ ç‰¹æ€§è¯´æ˜

### LangGraph çŠ¶æ€ç®¡ç†

ä½¿ç”¨ TypedDict å®šä¹‰ LangGraph çŠ¶æ€ï¼š

```python
class GraphState(TypedDict):
    """LangGraph çŠ¶æ€ï¼ˆç®€åŒ–ç‰ˆï¼Œç”¨äºå›¾ä¼ é€’ï¼‰"""
    
    # è¾“å…¥
    start_url: str
    task: str
    target_text: str
    max_steps: int
    output_dir: str
    
    # è¿è¡Œæ—¶çŠ¶æ€
    step_index: int
    page_url: str
    page_title: str
    
    # è§‚å¯Ÿç»“æœ
    screenshot_base64: str
    marks_text: str
    mark_id_to_xpath: dict[int, list[str]]
    scroll_info: dict | None
    
    # åŠ¨ä½œ
    current_action: dict | None
    action_result: dict | None
    
    # è„šæœ¬æ²‰æ·€
    script_steps: list[dict]
    
    # çŠ¶æ€æ ‡å¿—
    done: bool
    success: bool
    error: str | None
    fail_count: int
    extracted_text: str | None
```

### ç›®æ ‡æ–‡æœ¬æ£€æµ‹

è‡ªåŠ¨æ£€æµ‹é¡µé¢ä¸­æ˜¯å¦å­˜åœ¨ç›®æ ‡æ–‡æœ¬ï¼š

```python
# æ£€æŸ¥é¡µé¢ä¸­æ˜¯å¦å­˜åœ¨ç›®æ ‡æ–‡æœ¬ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
page_text = await page.evaluate("document.body.innerText")

if target_text in page_text:
    target_found_in_page = True
    print(f"âœ“ é¡µé¢ä¸­å‘ç°ç›®æ ‡æ–‡æœ¬ã€Œ{target_text}ã€")
    
    # å°è¯•å®šä½åŒ…å«ç›®æ ‡æ–‡æœ¬çš„å…ƒç´ 
    locator = page.locator(f"text={target_text}").first
    if await locator.count() > 0:
        bbox = await locator.bounding_box()
        text = await locator.inner_text()
        target_element_info = {
            "text": text[:200] if text else "",
            "bbox": bbox,
        }
```

### è„šæœ¬æ²‰æ·€

è‡ªåŠ¨æ²‰æ·€å¯å¤ç”¨çš„ XPath è„šæœ¬æ­¥éª¤ï¼š

```python
# è®°å½•è„šæœ¬æ­¥éª¤
if script_step:
    script_step.screenshot_context = f"step_{step_index:03d}.png"
    state["script_steps"].append(script_step.model_dump())

# ç”Ÿæˆæœ€ç»ˆè„šæœ¬
script = XPathScript(
    task=state["task"],
    start_url=state["start_url"],
    target_text=state["target_text"],
    steps=[ScriptStep(**s) for s in state["script_steps"]],
    extracted_result=state["extracted_text"],
    created_at=datetime.now().isoformat(),
)
```

---

## ğŸ”§ ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬ä½¿ç”¨

```python
import asyncio
from playwright.async_api import async_playwright
from autospider.extractor.graph.agent import run_agent
from autospider.common.types import RunInput

async def run_task():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        page = await browser.new_page()

        # åˆ›å»ºè¿è¡Œè¾“å…¥
        run_input = RunInput(
            start_url="https://example.com/products",
            task="æ”¶é›†æ‰€æœ‰å•†å“çš„ä»·æ ¼ä¿¡æ¯",
            target_text="ä»·æ ¼",
            max_steps=20,
            output_dir="output"
        )

        # è¿è¡Œ Agent
        script = await run_agent(page, run_input)

        print(f"ä»»åŠ¡: {script.task}")
        print(f"æ­¥éª¤æ•°: {len(script.steps)}")
        print(f"æå–ç»“æœ: {script.extracted_result}")

        await browser.close()

# è¿è¡Œ
asyncio.run(run_task())
```

### è‡ªå®šä¹‰æœ€å¤§æ­¥éª¤æ•°

```python
# è‡ªå®šä¹‰æœ€å¤§æ­¥éª¤æ•°
run_input = RunInput(
    start_url="https://example.com",
    task="æå–æ–‡ç« æ ‡é¢˜",
    target_text="æ ‡é¢˜",
    max_steps=50,  # æœ€å¤š 50 æ­¥
    output_dir="output"
)

script = await run_agent(page, run_input)
```

### æŸ¥çœ‹è„šæœ¬æ­¥éª¤

```python
# æŸ¥çœ‹ç”Ÿæˆçš„è„šæœ¬æ­¥éª¤
for i, step in enumerate(script.steps, 1):
    print(f"æ­¥éª¤ {i}:")
    print(f"  åŠ¨ä½œ: {step.action}")
    print(f"  ç›®æ ‡ XPath: {step.target_xpath}")
    print(f"  æ€è€ƒ: {step.thinking}")
    print(f"  æˆªå›¾: {step.screenshot_context}")
```

---

## ğŸ“ æœ€ä½³å®è·µ

### ä»»åŠ¡è®¾è®¡

1. **æ¸…æ™°çš„ä»»åŠ¡æè¿°**ï¼šæä¾›æ¸…æ™°ã€å…·ä½“çš„ä»»åŠ¡æè¿°
2. **å‡†ç¡®çš„ç›®æ ‡æ–‡æœ¬**ï¼šæä¾›å‡†ç¡®çš„ç›®æ ‡æ–‡æœ¬ç”¨äºåŒ¹é…
3. **åˆç†çš„æ­¥éª¤é™åˆ¶**ï¼šè®¾ç½®åˆç†çš„æœ€å¤§æ­¥éª¤æ•°

### Agent é…ç½®

1. **é€‰æ‹©åˆé€‚çš„æ¨¡å‹**ï¼šæ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©åˆé€‚çš„æ¨¡å‹
2. **è®¾ç½®åˆç†çš„å‚æ•°**ï¼šæ ¹æ®å®é™…éœ€æ±‚è®¾ç½® temperature å’Œ max_tokens
3. **ç›‘æ§æ‰§è¡Œè¿‡ç¨‹**ï¼šç›‘æ§ Agent æ‰§è¡Œè¿‡ç¨‹ä¾¿äºè°ƒè¯•

### è„šæœ¬ä½¿ç”¨

1. **éªŒè¯è„šæœ¬å‡†ç¡®æ€§**ï¼šéªŒè¯ç”Ÿæˆçš„è„šæœ¬æ˜¯å¦å‡†ç¡®
2. **æµ‹è¯•è„šæœ¬æ‰§è¡Œ**ï¼šæµ‹è¯•è„šæœ¬æ˜¯å¦å¯ä»¥æ­£å¸¸æ‰§è¡Œ
3. **ä¼˜åŒ–è„šæœ¬æ€§èƒ½**ï¼šä¼˜åŒ–è„šæœ¬æ€§èƒ½æé«˜æ‰§è¡Œæ•ˆç‡

---

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **Agent æ‰§è¡Œå¤±è´¥**
   - æ£€æŸ¥ä»»åŠ¡æè¿°æ˜¯å¦æ¸…æ™°
   - éªŒè¯ç›®æ ‡æ–‡æœ¬æ˜¯å¦å‡†ç¡®
   - ç¡®è®¤é¡µé¢åŠ è½½å®Œæˆ

2. **è„šæœ¬ç”Ÿæˆå¤±è´¥**
   - æ£€æŸ¥åŠ¨ä½œæ‰§è¡Œæ˜¯å¦æˆåŠŸ
   - éªŒè¯è„šæœ¬æ­¥éª¤æ˜¯å¦å®Œæ•´
   - ç¡®è®¤æˆªå›¾æ˜¯å¦ä¿å­˜æˆåŠŸ

3. **ç›®æ ‡æ–‡æœ¬æœªæ‰¾åˆ°**
   - æ£€æŸ¥ç›®æ ‡æ–‡æœ¬æ˜¯å¦æ­£ç¡®
   - éªŒè¯é¡µé¢æ˜¯å¦åŒ…å«ç›®æ ‡æ–‡æœ¬
   - ç¡®è®¤æ–‡æœ¬åŒ¹é…é€»è¾‘æ˜¯å¦æ­£ç¡®

### è°ƒè¯•æŠ€å·§

```python
# æ£€æŸ¥ Agent çŠ¶æ€
print(f"å½“å‰æ­¥éª¤: {state['step_index']}")
print(f"å½“å‰ URL: {state['page_url']}")
print(f"å½“å‰æ ‡é¢˜: {state['page_title']}")
print(f"æ˜¯å¦å®Œæˆ: {state['done']}")
print(f"æ˜¯å¦æˆåŠŸ: {state['success']}")
print(f"å¤±è´¥æ¬¡æ•°: {state['fail_count']}")
print(f"æå–æ–‡æœ¬: {state['extracted_text']}")

# æ£€æŸ¥è„šæœ¬æ­¥éª¤
print(f"è„šæœ¬æ­¥éª¤æ•°: {len(state['script_steps'])}")
for i, step in enumerate(state['script_steps'], 1):
    print(f"æ­¥éª¤ {i}: {step}")

# æ£€æŸ¥æˆªå›¾æ–‡ä»¶
import os
screenshot_files = os.listdir(screenshots_dir)
print(f"æˆªå›¾æ–‡ä»¶æ•°: {len(screenshot_files)}")
```

---

## ğŸ“š æ–¹æ³•å‚è€ƒ

### SoMAgent æ–¹æ³•

| æ–¹æ³• | å‚æ•° | è¿”å›å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `run()` | æ—  | XPathScript | è¿è¡Œ Agent å¹¶è¿”å› XPath è„šæœ¬ |
| `_observe()` | state | GraphState | è§‚å¯ŸèŠ‚ç‚¹ï¼šæ³¨å…¥ SoM + æˆªå›¾ |
| `_decide()` | state | GraphState | å†³ç­–èŠ‚ç‚¹ï¼šè°ƒç”¨ LLM |
| `_act()` | state | GraphState | æ‰§è¡ŒèŠ‚ç‚¹ï¼šæ‰§è¡ŒåŠ¨ä½œ |
| `_check_done()` | state | GraphState | æ£€æŸ¥æ˜¯å¦å®Œæˆ |
| `_generate_script()` | state | XPathScript | ç”Ÿæˆæœ€ç»ˆçš„ XPath è„šæœ¬ |

### ä¾¿æ·å‡½æ•°

| å‡½æ•° | å‚æ•° | è¿”å›å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `run_agent()` | page, run_input | XPathScript | è¿è¡Œ Agent çš„ä¾¿æ·å‡½æ•° |

---

## ğŸ“„ è„šæœ¬æ ¼å¼

### XPathScript

```python
{
    "task": "æ”¶é›†å•†å“ä»·æ ¼ä¿¡æ¯",
    "start_url": "https://example.com/products",
    "target_text": "ä»·æ ¼",
    "steps": [
        {
            "step": 1,
            "action": "click",
            "target_xpath": "//a[@class='product-link']",
            "xpath_alternatives": ["//div[@class='product']//a"],
            "thinking": "ç‚¹å‡»å•†å“é“¾æ¥è¿›å…¥è¯¦æƒ…é¡µ",
            "screenshot_context": "step_001.png"
        },
        {
            "step": 2,
            "action": "extract",
            "target_xpath": "//span[@class='price']",
            "xpath_alternatives": ["//div[@class='price']"],
            "thinking": "æå–ä»·æ ¼ä¿¡æ¯",
            "screenshot_context": "step_002.png"
        }
    ],
    "extracted_result": "Â¥99.00",
    "created_at": "2026-01-08T10:00:00"
}
```

---

*æœ€åæ›´æ–°: 2026-01-08*
