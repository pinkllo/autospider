# url_extractor.py - URL æå–å™¨

url_extractor.py æ¨¡å—æä¾› URL æå–åŠŸèƒ½ï¼Œè´Ÿè´£ä»å…ƒç´ ä¸­æå– URLã€‚

---

## ğŸ“ æ–‡ä»¶è·¯å¾„

```
src/autospider/extractor/collector/url_extractor.py
```

---

## ğŸ“‘ å‡½æ•°ç›®å½•

### ğŸš€ æ ¸å¿ƒç±»
- `URLExtractor` - URL æå–å™¨ä¸»ç±»

### ğŸ”§ ä¸»è¦æ–¹æ³•
- `extract_from_element()` - ä»å…ƒç´ ä¸­æå– URL
- `click_and_get_url()` - ç‚¹å‡»å…ƒç´ å¹¶è·å–æ–°é¡µé¢çš„ URL
- `click_element_and_get_url()` - ç‚¹å‡» locator å¹¶è·å– URL

---

## ğŸš€ æ ¸å¿ƒåŠŸèƒ½

### URLExtractor

URL æå–å™¨ï¼Œè´Ÿè´£ä»é¡µé¢å…ƒç´ ä¸­æå–è¯¦æƒ…é¡µ URLã€‚

```python
from autospider.extractor.collector.url_extractor import URLExtractor

# åˆ›å»º URL æå–å™¨
extractor = URLExtractor(page, list_url)

# ä»å…ƒç´ ä¸­æå– URL
url = await extractor.extract_from_element(
    element=element,
    snapshot=snapshot,
    nav_steps=nav_steps
)

print(f"æå–çš„ URL: {url}")
```

### æå–ç­–ç•¥

ä½¿ç”¨ä¸¤ç§ç­–ç•¥æå– URLï¼š

**ç­–ç•¥ 1: ä» href æå–**
```python
if element.href:
    url = urljoin(self.list_url, element.href)
    return url
```

**ç­–ç•¥ 2: ç‚¹å‡»è·å–**
```python
url = await self.click_and_get_url(element, nav_steps=nav_steps)
return url
```

---

## ğŸ’¡ ç‰¹æ€§è¯´æ˜

### ä¼˜å…ˆä» href æå–

ä¼˜å…ˆä»å…ƒç´ çš„ href å±æ€§æå– URLï¼Œé¿å…ä¸å¿…è¦çš„ç‚¹å‡»ï¼š

```python
if element.href:
    url = urljoin(self.list_url, element.href)
    print(f"âœ“ ä» href æå–: {url[:60]}...")
    return url
```

### æ–°æ ‡ç­¾é¡µæ£€æµ‹

è‡ªåŠ¨æ£€æµ‹æ–°æ ‡ç­¾é¡µçš„æ‰“å¼€ï¼š

```python
context = self.page.context
pages_before = len(context.pages)

# ç‚¹å‡»å…ƒç´ 
await element.click()

# æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ ‡ç­¾é¡µæ‰“å¼€
pages_after = len(context.pages)
if pages_after > pages_before:
    new_page = context.pages[-1]
    url = new_page.url
```

### å¯¼èˆªæ­¥éª¤é‡æ”¾

åœ¨è¿”å›åˆ—è¡¨é¡µæ—¶é‡æ”¾å¯¼èˆªæ­¥éª¤ï¼š

```python
# è¿”å›åˆ—è¡¨é¡µ
await self.page.goto(self.list_url, wait_until="domcontentloaded", timeout=30000)

# é‡æ”¾å¯¼èˆªæ­¥éª¤
if nav_steps:
    for step in nav_steps:
        # æ‰§è¡Œå¯¼èˆªæ­¥éª¤
        pass
```

---

## ğŸ”§ ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬ä½¿ç”¨

```python
from autospider.extractor.collector.url_extractor import URLExtractor

# åˆ›å»º URL æå–å™¨
extractor = URLExtractor(page, list_url="https://example.com/list")

# ä»å…ƒç´ ä¸­æå– URL
url = await extractor.extract_from_element(
    element=element,
    snapshot=snapshot,
    nav_steps=[]
)

print(f"æå–çš„ URL: {url}")
```

### ç‚¹å‡»è·å– URL

```python
# ç‚¹å‡»å…ƒç´ å¹¶è·å– URL
url = await extractor.click_and_get_url(
    element=element,
    nav_steps=nav_steps
)

print(f"ç‚¹å‡»åè·å–çš„ URL: {url}")
```

### ä½¿ç”¨ locator

```python
# ä½¿ç”¨ locator æå– URL
locator = page.locator("//a[@class='product-link']")

url = await extractor.click_element_and_get_url(
    locator=locator,
    nav_steps=nav_steps
)

print(f"æå–çš„ URL: {url}")
```

---

## ğŸ“ æœ€ä½³å®è·µ

### URL æå–

1. **ä¼˜å…ˆä½¿ç”¨ href**ï¼šä¼˜å…ˆä» href å±æ€§æå– URL
2. **éªŒè¯ URL æœ‰æ•ˆæ€§**ï¼šéªŒè¯æå–çš„ URL æ˜¯å¦æœ‰æ•ˆ
3. **å¤„ç†ç›¸å¯¹è·¯å¾„**ï¼šæ­£ç¡®å¤„ç†ç›¸å¯¹è·¯å¾„è½¬æ¢ä¸ºç»å¯¹è·¯å¾„

### æ–°æ ‡ç­¾é¡µå¤„ç†

1. **æ£€æµ‹æ–°æ ‡ç­¾é¡µ**ï¼šè‡ªåŠ¨æ£€æµ‹æ–°æ ‡ç­¾é¡µçš„æ‰“å¼€
2. **åˆ‡æ¢åˆ°æ–°æ ‡ç­¾é¡µ**ï¼šè‡ªåŠ¨åˆ‡æ¢åˆ°æ–°æ ‡ç­¾é¡µ
3. **å…³é—­æ—§æ ‡ç­¾é¡µ**ï¼šæ ¹æ®éœ€è¦å…³é—­æ—§æ ‡ç­¾é¡µ

### å¯¼èˆªæ­¥éª¤é‡æ”¾

1. **ä¿å­˜å¯¼èˆªæ­¥éª¤**ï¼šä¿å­˜å¯¼èˆªæ­¥éª¤ä»¥ä¾¿é‡æ”¾
2. **é‡æ”¾å¯¼èˆªæ­¥éª¤**ï¼šåœ¨è¿”å›åˆ—è¡¨é¡µæ—¶é‡æ”¾å¯¼èˆªæ­¥éª¤
3. **éªŒè¯é‡æ”¾ç»“æœ**ï¼šéªŒè¯å¯¼èˆªæ­¥éª¤é‡æ”¾æ˜¯å¦æˆåŠŸ

---

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **URL æå–å¤±è´¥**
   - æ£€æŸ¥å…ƒç´ æ˜¯å¦æœ‰ href å±æ€§
   - éªŒè¯å…ƒç´ æ˜¯å¦å¯ç‚¹å‡»
   - ç¡®è®¤é¡µé¢åŠ è½½å®Œæˆ

2. **æ–°æ ‡ç­¾é¡µå¤„ç†å¤±è´¥**
   - æ£€æŸ¥æ–°æ ‡ç­¾é¡µæ˜¯å¦æ­£ç¡®æ‰“å¼€
   - éªŒè¯æ ‡ç­¾é¡µåˆ‡æ¢é€»è¾‘æ˜¯å¦æ­£ç¡®
   - ç¡®è®¤ URL æ˜¯å¦æ­£ç¡®è·å–

3. **å¯¼èˆªæ­¥éª¤é‡æ”¾å¤±è´¥**
   - æ£€æŸ¥å¯¼èˆªæ­¥éª¤æ˜¯å¦æ­£ç¡®
   - éªŒè¯å…ƒç´ é€‰æ‹©å™¨æ˜¯å¦æœ‰æ•ˆ
   - ç¡®è®¤é¡µé¢çŠ¶æ€æ˜¯å¦æ­£ç¡®

### è°ƒè¯•æŠ€å·§

```python
# æ£€æŸ¥å…ƒç´ ä¿¡æ¯
print(f"å…ƒç´  tag: {element.tag}")
print(f"å…ƒç´  text: {element.text}")
print(f"å…ƒç´  href: {element.href}")
print(f"å…ƒç´  role: {element.role}")

# æ£€æŸ¥æå–çš„ URL
print(f"æå–çš„ URL: {url}")
print(f"URL é•¿åº¦: {len(url)}")

# æ£€æŸ¥é¡µé¢çŠ¶æ€
print(f"å½“å‰ URL: {page.url}")
print(f"æ ‡ç­¾é¡µæ•°: {len(page.context.pages)}")
```

---

## ğŸ“š æ–¹æ³•å‚è€ƒ

### URLExtractor æ–¹æ³•

| æ–¹æ³• | å‚æ•° | è¿”å›å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `extract_from_element()` | element, snapshot, nav_steps | str \| None | ä»å…ƒç´ ä¸­æå– URL |
| `click_and_get_url()` | element, nav_steps | str \| None | ç‚¹å‡»å…ƒç´ å¹¶è·å–æ–°é¡µé¢çš„ URL |
| `click_element_and_get_url()` | locator, nav_steps | str \| None | ç‚¹å‡» locator å¹¶è·å– URL |

---

*æœ€åæ›´æ–°: 2026-01-08*
