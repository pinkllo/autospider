# resume_strategy.py - æ–­ç‚¹æ¢å¤ç­–ç•¥

resume_strategy.py æ¨¡å—å®ç°ä¸‰çº§æ–­ç‚¹å®šä½ç­–ç•¥ï¼Œç”¨äºåœ¨çˆ¬è™«ä¸­æ–­åå¿«é€Ÿæ¢å¤åˆ°ç›®æ ‡é¡µã€‚

---

## ğŸ“ æ–‡ä»¶è·¯å¾„

```
src/autospider/crawler/checkpoint/resume_strategy.py
```

---

## ğŸ“‘ å‡½æ•°ç›®å½•

### ğŸš€ æ ¸å¿ƒç±»
- `ResumeStrategy` - æ¢å¤ç­–ç•¥åŸºç±»ï¼ˆæŠ½è±¡ç±»ï¼‰
- `URLPatternStrategy` - ç­–ç•¥ä¸€ï¼šURL è§„å¾‹çˆ†ç ´
- `WidgetJumpStrategy` - ç­–ç•¥äºŒï¼šæ§ä»¶ç›´è¾¾
- `SmartSkipStrategy` - ç­–ç•¥ä¸‰ï¼šé¦–é¡¹æ£€æµ‹ä¸å›æº¯
- `ResumeCoordinator` - æ¢å¤åè°ƒå™¨

### ğŸ”§ ä¸»è¦æ–¹æ³•
- `try_resume()` - å°è¯•æ¢å¤åˆ°ç›®æ ‡é¡µ
- `resume_to_page()` - æŒ‰ä¼˜å…ˆçº§å°è¯•æ¢å¤åˆ°ç›®æ ‡é¡µ

### ğŸ” å†…éƒ¨æ–¹æ³•
- `_detect_page_param()` - æ£€æµ‹ URL ä¸­çš„é¡µç å‚æ•°å
- `_build_url_for_page()` - æ„é€ ç›®æ ‡é¡µçš„ URL
- `_get_first_url()` - è·å–åˆ—è¡¨é¡µç¬¬ä¸€æ¡æ•°æ®çš„ URL
- `_click_next_page()` - ç‚¹å‡»ä¸‹ä¸€é¡µ
- `_click_prev_page()` - ç‚¹å‡»ä¸Šä¸€é¡µï¼ˆç”¨äºå›æº¯ï¼‰

---

## ğŸš€ æ ¸å¿ƒåŠŸèƒ½

### ä¸‰çº§æ–­ç‚¹å®šä½ç­–ç•¥

æ¨¡å—å®ç°ä¸‰çº§æ–­ç‚¹å®šä½ç­–ç•¥ï¼ŒæŒ‰ä¼˜å…ˆçº§å°è¯•æ¢å¤ï¼š

**ç­–ç•¥ä¸€ï¼šURL è§„å¾‹çˆ†ç ´**
```python
# åˆ†æåˆ—è¡¨é¡µ URL æ˜¯å¦åŒ…å« page=xx å‚æ•°ï¼Œç›´æ¥æ„é€ è·³è½¬
strategy = URLPatternStrategy(list_url)
success, actual_page = await strategy.try_resume(page, target_page)
```

**ç­–ç•¥äºŒï¼šæ§ä»¶ç›´è¾¾**
```python
# ä½¿ç”¨æå–çš„è·³è½¬æ§ä»¶ xpath è¿›è¡Œè·³è½¬
strategy = WidgetJumpStrategy(jump_widget_xpath)
success, actual_page = await strategy.try_resume(page, target_page)
```

**ç­–ç•¥ä¸‰ï¼šé¦–é¡¹æ£€æµ‹ä¸å›æº¯**
```python
# ä»ç¬¬ 1 é¡µå¼€å§‹ï¼Œåªæ£€æµ‹ç¬¬ä¸€æ¡æ•°æ®ï¼Œå¿«é€Ÿè·³è¿‡å·²çˆ¬é¡µé¢
strategy = SmartSkipStrategy(collected_urls, detail_xpath, pagination_xpath)
success, actual_page = await strategy.try_resume(page, target_page)
```

### ResumeCoordinator

æ¢å¤åè°ƒå™¨ï¼ŒæŒ‰ä¼˜å…ˆçº§å°è¯•å„ç­–ç•¥ï¼š

```python
from autospider.crawler.checkpoint.resume_strategy import ResumeCoordinator

# åˆ›å»ºæ¢å¤åè°ƒå™¨
coordinator = ResumeCoordinator(
    list_url="https://example.com/list",
    collected_urls=set(collected_urls),
    jump_widget_xpath=jump_widget_xpath,
    detail_xpath=detail_xpath,
    pagination_xpath=pagination_xpath,
)

# æŒ‰ä¼˜å…ˆçº§å°è¯•æ¢å¤åˆ°ç›®æ ‡é¡µ
actual_page = await coordinator.resume_to_page(page, target_page_num)
```

---

## ğŸ’¡ ç‰¹æ€§è¯´æ˜

### ç­–ç•¥ä¸€ï¼šURL è§„å¾‹çˆ†ç ´

åˆ†æåˆ—è¡¨é¡µ URL æ˜¯å¦åŒ…å«é¡µç å‚æ•°ï¼Œç›´æ¥æ„é€ è·³è½¬ã€‚

```python
class URLPatternStrategy(ResumeStrategy):
    """ç­–ç•¥ä¸€: URL è§„å¾‹çˆ†ç ´
    
    åˆ†æåˆ—è¡¨é¡µ URL æ˜¯å¦åŒ…å« page=xx å‚æ•°ï¼Œç›´æ¥æ„é€ è·³è½¬ã€‚
    """
    
    def _detect_page_param(self) -> str | None:
        """æ£€æµ‹ URL ä¸­çš„é¡µç å‚æ•°å"""
        # å¸¸è§çš„é¡µç å‚æ•°å
        common_page_params = ["page", "p", "pageNum", "pageNo", "pn", "offset"]
        
        for param in common_page_params:
            if param in params:
                return param
        
        return None
```

**ä¼˜ç‚¹**ï¼š
- æœ€å¿«é€Ÿï¼Œç›´æ¥æ„é€  URL è·³è½¬
- ä¸éœ€è¦é¡µé¢äº¤äº’

**ç¼ºç‚¹**ï¼š
- åªé€‚ç”¨äº URL åŒ…å«é¡µç å‚æ•°çš„ç½‘ç«™
- å¯èƒ½è¢«æœåŠ¡å™¨é‡å®šå‘

### ç­–ç•¥äºŒï¼šæ§ä»¶ç›´è¾¾

ä½¿ç”¨æå–çš„è·³è½¬æ§ä»¶ xpath è¿›è¡Œè·³è½¬ã€‚

```python
class WidgetJumpStrategy(ResumeStrategy):
    """ç­–ç•¥äºŒ: é¡µç æ§ä»¶ç›´è¾¾
    
    ä½¿ç”¨ Phase 3.6 æå–çš„è·³è½¬æ§ä»¶ xpath è¿›è¡Œè·³è½¬ã€‚
    """
    
    async def try_resume(self, page: "Page", target_page: int) -> tuple[bool, int]:
        """å°è¯•é€šè¿‡é¡µç è¾“å…¥æ§ä»¶è·³è½¬"""
        # æ¸…ç©ºå¹¶è¾“å…¥é¡µç 
        await input_locator.first.fill(str(target_page))
        
        # ç‚¹å‡»ç¡®å®šæŒ‰é’®
        await button_locator.first.click()
```

**ä¼˜ç‚¹**ï¼š
- é€‚ç”¨äºå¤§å¤šæ•°åˆ†é¡µç½‘ç«™
- å‡†ç¡®æ€§é«˜

**ç¼ºç‚¹**ï¼š
- éœ€è¦æå‰æå–è·³è½¬æ§ä»¶ xpath
- ä¾èµ–é¡µé¢ç»“æ„ç¨³å®šæ€§

### ç­–ç•¥ä¸‰ï¼šé¦–é¡¹æ£€æµ‹ä¸å›æº¯

ä»ç¬¬ 1 é¡µå¼€å§‹ï¼Œåªæ£€æµ‹ç¬¬ä¸€æ¡æ•°æ®ï¼Œå¿«é€Ÿè·³è¿‡å·²çˆ¬é¡µé¢ã€‚

```python
class SmartSkipStrategy(ResumeStrategy):
    """ç­–ç•¥ä¸‰: é¦–é¡¹æ£€æµ‹ä¸å›æº¯ (å…œåº•æ–¹æ¡ˆ)
    
    ä»ç¬¬ 1 é¡µå¼€å§‹ï¼Œåªæ£€æµ‹ç¬¬ä¸€æ¡æ•°æ®ï¼Œå¿«é€Ÿè·³è¿‡å·²çˆ¬é¡µé¢ã€‚
    å½“æ£€æµ‹åˆ°ç¬¬ä¸€æ¡æ–°æ•°æ®æ—¶ï¼Œå›é€€ä¸€é¡µä»¥ç¡®ä¿å®Œæ•´æ€§ã€‚
    """
    
    async def try_resume(self, page: "Page", target_page: int) -> tuple[bool, int]:
        """é€šè¿‡é¦–é¡¹æ£€æµ‹å¿«é€Ÿè·³è¿‡å·²çˆ¬é¡µé¢"""
        # è·å–å½“å‰é¡µç¬¬ä¸€æ¡ URL
        first_url = await self._get_first_url(page)
        
        # æ£€æŸ¥é¦–æ¡ URL æ˜¯å¦å·²å­˜åœ¨
        if first_url in self.collected_urls:
            # ç‚¹å‡»ä¸‹ä¸€é¡µ
            await self._click_next_page(page)
        else:
            # å›æº¯ä¸€é¡µä»¥ç¡®ä¿å®Œæ•´æ€§
            if current_page > 1:
                await self._click_prev_page(page)
```

**ä¼˜ç‚¹**ï¼š
- é€‚ç”¨äºæ‰€æœ‰åˆ†é¡µç½‘ç«™
- ä¸ä¾èµ–é¡µé¢ç»“æ„

**ç¼ºç‚¹**ï¼š
- é€Ÿåº¦è¾ƒæ…¢ï¼Œéœ€è¦é€é¡µæ£€æµ‹
- å¯èƒ½éœ€è¦å¤šæ¬¡ç¿»é¡µ

---

## ğŸ”§ ä½¿ç”¨ç¤ºä¾‹

### ä½¿ç”¨æ¢å¤åè°ƒå™¨

```python
import asyncio
from playwright.async_api import async_playwright
from autospider.crawler.checkpoint.resume_strategy import ResumeCoordinator

async def resume_collection():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        page = await browser.new_page()

        # åˆ›å»ºæ¢å¤åè°ƒå™¨
        coordinator = ResumeCoordinator(
            list_url="https://example.com/list",
            collected_urls=set(collected_urls),
            jump_widget_xpath={
                "input": "//input[@class='page-input']",
                "button": "//button[@class='jump-btn']"
            },
            detail_xpath="//a[@class='product-link']",
            pagination_xpath="//a[contains(text(),'ä¸‹ä¸€é¡µ')]",
        )

        # æŒ‰ä¼˜å…ˆçº§å°è¯•æ¢å¤åˆ°ç›®æ ‡é¡µ
        target_page_num = 10
        actual_page = await coordinator.resume_to_page(page, target_page_num)

        print(f"å·²æ¢å¤åˆ°ç¬¬ {actual_page} é¡µ")

        await browser.close()

# è¿è¡Œ
asyncio.run(resume_collection())
```

### å•ç‹¬ä½¿ç”¨ç­–ç•¥

```python
from autospider.crawler.checkpoint.resume_strategy import (
    URLPatternStrategy,
    WidgetJumpStrategy,
    SmartSkipStrategy
)

# ç­–ç•¥ä¸€ï¼šURL è§„å¾‹çˆ†ç ´
strategy1 = URLPatternStrategy(list_url="https://example.com/list?page=1")
success, actual_page = await strategy1.try_resume(page, target_page=10)

# ç­–ç•¥äºŒï¼šæ§ä»¶ç›´è¾¾
strategy2 = WidgetJumpStrategy(jump_widget_xpath={
    "input": "//input[@class='page-input']",
    "button": "//button[@class='jump-btn']"
})
success, actual_page = await strategy2.try_resume(page, target_page=10)

# ç­–ç•¥ä¸‰ï¼šé¦–é¡¹æ£€æµ‹ä¸å›æº¯
strategy3 = SmartSkipStrategy(
    collected_urls=set(collected_urls),
    detail_xpath="//a[@class='product-link']",
    pagination_xpath="//a[contains(text(),'ä¸‹ä¸€é¡µ')]"
)
success, actual_page = await strategy3.try_resume(page, target_page=10)
```

---

## ğŸ“ æœ€ä½³å®è·µ

### ç­–ç•¥é€‰æ‹©

1. **ä¼˜å…ˆä½¿ç”¨ç­–ç•¥ä¸€**ï¼šå¦‚æœ URL åŒ…å«é¡µç å‚æ•°ï¼Œä¼˜å…ˆä½¿ç”¨ URL è§„å¾‹çˆ†ç ´
2. **æ¬¡é€‰ç­–ç•¥äºŒ**ï¼šå¦‚æœå·²æå–è·³è½¬æ§ä»¶ xpathï¼Œä½¿ç”¨æ§ä»¶ç›´è¾¾
3. **å…œåº•ç­–ç•¥ä¸‰**ï¼šå¦‚æœå‰ä¸¤ä¸ªç­–ç•¥éƒ½å¤±è´¥ï¼Œä½¿ç”¨é¦–é¡¹æ£€æµ‹ä¸å›æº¯

### æ€§èƒ½ä¼˜åŒ–

1. **æå‰æå– xpath**ï¼šåœ¨æ¢ç´¢é˜¶æ®µæå–è·³è½¬æ§ä»¶ xpath
2. **ç¼“å­˜æ£€æµ‹ç»“æœ**ï¼šç¼“å­˜é¦–æ¡ URL æ£€æµ‹ç»“æœ
3. **é™åˆ¶è·³è¿‡é¡µæ•°**ï¼šè®¾ç½®æœ€å¤§è·³è¿‡é¡µæ•°é¿å…æ— é™å¾ªç¯

### é”™è¯¯å¤„ç†

1. **æ•è·å¼‚å¸¸**ï¼šå¦¥å–„å¤„ç†å„ç§å¼‚å¸¸æƒ…å†µ
2. **éªŒè¯ç»“æœ**ï¼šéªŒè¯è·³è½¬æ˜¯å¦æˆåŠŸ
3. **è®°å½•æ—¥å¿—**ï¼šè¯¦ç»†è®°å½•æ¢å¤è¿‡ç¨‹

---

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **ç­–ç•¥ä¸€å¤±è´¥**
   - æ£€æŸ¥ URL æ˜¯å¦åŒ…å«é¡µç å‚æ•°
   - éªŒè¯é¡µç å‚æ•°åæ˜¯å¦æ­£ç¡®
   - ç¡®è®¤ URL æ„é€ æ˜¯å¦æ­£ç¡®

2. **ç­–ç•¥äºŒå¤±è´¥**
   - æ£€æŸ¥è·³è½¬æ§ä»¶ xpath æ˜¯å¦æ­£ç¡®
   - éªŒè¯æ§ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¯è§
   - ç¡®è®¤æ§ä»¶æ˜¯å¦å¯äº¤äº’

3. **ç­–ç•¥ä¸‰å¤±è´¥**
   - æ£€æŸ¥è¯¦æƒ…é¡µ xpath æ˜¯å¦æ­£ç¡®
   - éªŒè¯åˆ†é¡µæ§ä»¶ xpath æ˜¯å¦æ­£ç¡®
   - ç¡®è®¤å·²æ”¶é›† URL é›†åˆæ˜¯å¦æ­£ç¡®

4. **æ‰€æœ‰ç­–ç•¥å¤±è´¥**
   - æ£€æŸ¥é¡µé¢ç»“æ„æ˜¯å¦å‘ç”Ÿå˜åŒ–
   - éªŒè¯ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸
   - ç¡®è®¤ç›®æ ‡é¡µç æ˜¯å¦æœ‰æ•ˆ

### è°ƒè¯•æŠ€å·§

```python
# æ£€æŸ¥ç­–ç•¥æ‰§è¡Œ
for i, strategy in enumerate(coordinator.strategies, 1):
    print(f"ç­–ç•¥ {i}: {strategy.name}")
    success, actual_page = await strategy.try_resume(page, target_page)
    print(f"  æˆåŠŸ: {success}, å®é™…é¡µ: {actual_page}")

# æ£€æŸ¥ URL å‚æ•°
parsed = urlparse(list_url)
params = parse_qs(parsed.query)
print(f"URL å‚æ•°: {params}")

# æ£€æŸ¥é¦–æ¡ URL
first_url = await strategy._get_first_url(page)
print(f"é¦–æ¡ URL: {first_url}")
print(f"å·²æ”¶é›†: {first_url in collected_urls}")
```

---

## ğŸ“š æ–¹æ³•å‚è€ƒ

### ResumeStrategy æ–¹æ³•

| æ–¹æ³• | å‚æ•° | è¿”å›å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `try_resume()` | page, target_page | tuple[bool, int] | å°è¯•æ¢å¤åˆ°ç›®æ ‡é¡µ |

### URLPatternStrategy æ–¹æ³•

| æ–¹æ³• | å‚æ•° | è¿”å›å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `_detect_page_param()` | æ—  | str \| None | æ£€æµ‹ URL ä¸­çš„é¡µç å‚æ•°å |
| `_build_url_for_page()` | target_page | str \| None | æ„é€ ç›®æ ‡é¡µçš„ URL |
| `try_resume()` | page, target_page | tuple[bool, int] | å°è¯•é€šè¿‡ URL ç›´æ¥è·³è½¬ |

### WidgetJumpStrategy æ–¹æ³•

| æ–¹æ³• | å‚æ•° | è¿”å›å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `try_resume()` | page, target_page | tuple[bool, int] | å°è¯•é€šè¿‡é¡µç è¾“å…¥æ§ä»¶è·³è½¬ |

### SmartSkipStrategy æ–¹æ³•

| æ–¹æ³• | å‚æ•° | è¿”å›å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `_get_first_url()` | page | str \| None | è·å–åˆ—è¡¨é¡µç¬¬ä¸€æ¡æ•°æ®çš„ URL |
| `_click_next_page()` | page | bool | ç‚¹å‡»ä¸‹ä¸€é¡µ |
| `_click_prev_page()` | page | bool | ç‚¹å‡»ä¸Šä¸€é¡µï¼ˆç”¨äºå›æº¯ï¼‰ |
| `try_resume()` | page, target_page | tuple[bool, int] | é€šè¿‡é¦–é¡¹æ£€æµ‹å¿«é€Ÿè·³è¿‡å·²çˆ¬é¡µé¢ |

### ResumeCoordinator æ–¹æ³•

| æ–¹æ³• | å‚æ•° | è¿”å›å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `resume_to_page()` | page, target_page | int | æŒ‰ä¼˜å…ˆçº§å°è¯•æ¢å¤åˆ°ç›®æ ‡é¡µ |

---

*æœ€åæ›´æ–°: 2026-01-08*
